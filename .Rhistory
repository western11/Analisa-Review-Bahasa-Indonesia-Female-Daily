bahasa.sw <- read.csv("Bahasa.stopwords.csv", header = F,fileEncoding = "UTF-8-BOM")
bahasa.sw <- as.character(bahasa.sw$V1)
bahasa.sw <- c(bahasa.sw, stopwords())
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_html() %>%
replace_url() %>%
replace_emoji() %>%
replace_internet_slang() %>% # replace internet slang to normal words
replace_word_elongation() %>% # reolace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw) %>%
tm_map(stemDocument)
return(DocumentTermMatrix(xdtm))
}
review.dtm <- textcleaner(dat$review)
freqterm <- findFreqTerms(review.dtm, 100)
freqterm <- findFreqTerms(review.dtm, 50)
freqterm <- findFreqTerms(review.dtm, 2)
freqterm <- findFreqTerms(review.dtm, 10)
freqterm <- findFreqTerms(review.dtm, 20)
freqterm <- findFreqTerms(review.dtm, 15)
dat_dtm <- review.dtm[,freqterm]
dat.clean <- as.data.frame(as.matrix(dat_dtm), stringsAsFactors = F)
# we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names
new.dat <- cbind(dat.clean, data.frame(labelY = dat$rating))
new.dat
freqterm <- findFreqTerms(review.dtm, 20)
textclean::replace_emoji()
textclean::replace_emoji()
textclean::replace_emoji
?textclean::replace_emoji
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_html(remove = T) %>%
replace_url(remove = T) %>%
replace_emoji(remove = T) %>%
replace_internet_slang() %>% # replace internet slang to normal words
replace_word_elongation() %>% # reolace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw)
return(DocumentTermMatrix(xdtm))
}
?textclea
review.dtm <- textcleaner(dat$review)
freqterm <- findFreqTerms(review.dtm, 20)
dat_dtm <- review.dtm[,freqterm]
freqterm
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(textclean)
library(tm)
library(SnowballC)
library(stringr)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(textclean)
library(tm)
library(SnowballC)
library(stringr)
stemmword <- function(x) Reduce(function(x,r) gsub(stemm_indo$old[r],stemm_indo$new[r],x,fixed=T),
seq_len(nrow(stemm_indo)),x)
slangword <- function(x) Reduce(function(x,r) gsub(slang_indo$old[r],slang_indo$new[r],x,fixed=T),
seq_len(nrow(slang_indo)),x)
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_internet_slang() %>% # replace internet slang to normal words
replace_emoji() %>%
replace_emoticon() %>%
replace_hash(replacement = "") %>%
replace_word_elongation() %>% # replace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
replace_time(replacement = "") %>%
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
trimws(gsub("\\w*[0-9]+\\w*\\s*", "", x = x)) %>%
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stemmword)) %>%
tm_map(content_transformer(slangword))
return(DocumentTermMatrix(xdtm))
}
review.dtm <- textcleaner(dat$review)
stemmword <- function(x) Reduce(function(x,r) gsub(stemm_indo$old[r],stemm_indo$new[r],x,fixed=T),
seq_len(nrow(stemm_indo)),x)
slangword <- function(x) Reduce(function(x,r) gsub(slang_indo$old[r],slang_indo$new[r],x,fixed=T),
seq_len(nrow(slang_indo)),x)
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_internet_slang() %>% # replace internet slang to normal words
replace_emoji() %>%
replace_emoticon() %>%
replace_hash(replacement = "") %>%
replace_word_elongation() %>% # replace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
replace_time(replacement = "") %>%
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
str_remove_all(pattern = "\\w*[0-9]+\\w*\\s*") %>%
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stemmword)) %>%
tm_map(content_transformer(slangword))
return(DocumentTermMatrix(xdtm))
}
review.dtm <- textcleaner(dat$review)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(textclean)
library(tm)
library(SnowballC)
library(stringr)
# add custom bahasa stopwords
bahasa.sw <- read.csv("Bahasa.stopwords.csv", header = F,fileEncoding = "UTF-8-BOM")
bahasa.sw <- as.character(bahasa.sw$V1)
bahasa.sw <- c(bahasa.sw, stopwords())
# add custom stemming and slangword bahasa indonesia
stemm_indo <- read.csv("Stemming.csv")
oldstem <- as.character(stemm_indo$old)
newstem <- as.character(stemm_indo$new)
slang_indo <- read.csv("Slangword.csv")
oldslang <- as.character(slang_indo$old)
newslang <- as.character(slang_indo$new)
dat <- read.csv("emina1.csv")
dat <- dat %>% rename(
"review" = "Ã¯..review"
) %>% select(review,rating) %>%
na.omit()
table(dat$rating)
head(dat$review)
stemmword <- function(x) Reduce(function(x,r) gsub(stemm_indo$old[r],stemm_indo$new[r],x,fixed=T),
seq_len(nrow(stemm_indo)),x)
slangword <- function(x) Reduce(function(x,r) gsub(slang_indo$old[r],slang_indo$new[r],x,fixed=T),
seq_len(nrow(slang_indo)),x)
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_internet_slang() %>% # replace internet slang to normal words
replace_emoji() %>%
replace_emoticon() %>%
replace_hash(replacement = "") %>%
replace_word_elongation() %>% # replace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
replace_time(replacement = "") %>%
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
str_remove_all(pattern = "\\w*[0-9]+\\w*\\s*") %>%
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stemmword)) %>%
tm_map(content_transformer(slangword))
return(DocumentTermMatrix(xdtm))
}
check_text(dat$review)
review.dtm <- textcleaner(dat$review)
freqterm <- findFreqTerms(review.dtm, 15)
freqterm <- findFreqTerms(review.dtm, 10)
dat_dtm <- review.dtm[,freqterm]
dat.clean <- as.data.frame(as.matrix(dat_dtm), stringsAsFactors = F)
# we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names
new.dat <- cbind(dat.clean, data.frame(labelY = dat$rating))
names(new.dat)
stemmword <- function(x) Reduce(function(x,r) gsub(stemm_indo$old[r],stemm_indo$new[r],x,fixed=T),
seq_len(nrow(stemm_indo)),x)
slangword <- function(x) Reduce(function(x,r) gsub(slang_indo$old[r],slang_indo$new[r],x,fixed=T),
seq_len(nrow(slang_indo)),x)
textcleaner <- function(x){
x <- as.character(x)
x <- x %>%
str_to_lower() %>%  # convert all the string to low alphabet
replace_contraction() %>% # replace contraction to their multi-word forms
replace_internet_slang() %>% # replace internet slang to normal words
replace_emoji() %>%
replace_emoticon() %>%
replace_hash(replacement = "") %>%
replace_word_elongation() %>% # replace informal writing with known semantic replacements
replace_number(remove = T) %>% # remove number
replace_date(replacement = "") %>% # remove date
replace_time(replacement = "") %>%
str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
str_remove_all(pattern = "[^\\s]*[0-9][^\\s]*") %>%
str_squish() %>% # reduces repeated whitespace inside a string.
str_trim() # removes whitespace from start and end of string
xdtm <- VCorpus(VectorSource(x)) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removeWords, bahasa.sw) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(stemmword)) %>%
tm_map(content_transformer(slangword))
return(DocumentTermMatrix(xdtm))
}
review.dtm <- textcleaner(dat$review)
freqterm <- findFreqTerms(review.dtm, 10)
freqterm <- findFreqTerms(review.dtm, 15)
dat_dtm <- review.dtm[,freqterm]
dat.clean <- as.data.frame(as.matrix(dat_dtm), stringsAsFactors = F)
# we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names
new.dat <- cbind(dat.clean, data.frame(labelY = dat$rating))
names(new.dat)
head(new.dat)
# split the data. 75% for train data, and 25% for test data
set.seed(1502)
index <- sample(1:nrow(dat_dtm), 0.75*nrow(dat_dtm))
train_x <- dat_dtm[index,]
test_x <- dat_dtm[-index,]
# subset label/target variable
train_label <- dat[index,"rating"]
test_label <- dat[-index,"rating"]
# bernoulli conv
bernoulli_conv <- function(x){
x <- as.factor(as.numeric(x>0))
}
train_x <- apply(train_x,2,bernoulli_conv)
test_x <- apply(test_x,2,bernoulli_conv)
# train the model
mod.nb <- naiveBayes(train_x, as.factor(train_label), laplace = 1)
library(e1071)
library(tidymodels)
# train the model
mod.nb <- naiveBayes(train_x, as.factor(train_label), laplace = 1)
# predict to test data
pred.nb <- predict(mod.nb, test_x,
type = "class")
pred.nb.x <- cbind(data.frame(pred.nb),test_label)%>%
setNames(c("pred","actual"))
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
reference = pred.nb.x$actual,
positive = "positive")
library(caret)
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
reference = pred.nb.x$actual,
positive = "positive")
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
reference = pred.nb.x$actual)
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
reference = pred.nb.x$actual)
pred.nb.x
pred.nb.x <- cbind(data.frame(pred.nb),as.factor(test_label))%>%
setNames(c("pred","actual"))
pred.nb.x
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
reference = pred.nb.x$actual)
cf.nb
set.seed(1502)
splitter <- initial_split(new.dat, prop = 0.75, strata = "labelY")
train <- training(splitter)
test <- testing(splitter)
# this chunks are made for random forest model and future model tuning
## the column names like break,for,next,if are considered as special character thus raises an error when building random forest and model tuning.
## i store the train and test data to new variabel so the old one remain reproducible
train_tune <- train
test_tune <- test
colnames(train_tune) <- make.names(colnames(train_tune))
colnames(test_tune) <- make.names(colnames(test_tune))
# build 5 folds cross validation for tuning evaluationn
set.seed(1502)
folds <- vfold_cv(train_tune, 5)
mod.rf <- rand_forest(trees = 550, mtry = 6, mode = "classification") %>%
set_engine("ranger") %>% fit(labelY~., data = train_tune)
dat$rating <- as.factor(dat$rating)
table(dat$rating)
dat.clean <- as.data.frame(as.matrix(dat_dtm), stringsAsFactors = F)
# we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names
new.dat <- cbind(dat.clean, data.frame(labelY = dat$rating))
str(new.dat$labelY)
# this chunks are made for random forest model and future model tuning
## the column names like break,for,next,if are considered as special character thus raises an error when building random forest and model tuning.
## i store the train and test data to new variabel so the old one remain reproducible
train_tune <- train
test_tune <- test
colnames(train_tune) <- make.names(colnames(train_tune))
colnames(test_tune) <- make.names(colnames(test_tune))
# build 5 folds cross validation for tuning evaluation
set.seed(1502)
folds <- vfold_cv(train_tune, 5)
mod.rf <- rand_forest(trees = 550, mtry = 6, mode = "classification") %>%
set_engine("ranger") %>% fit(labelY~., data = train_tune)
str(train_tune$labelY)
set.seed(1502)
splitter <- initial_split(new.dat, prop = 0.75, strata = "labelY")
train <- training(splitter)
test <- testing(splitter)
# this chunks are made for random forest model and future model tuning
## the column names like break,for,next,if are considered as special character thus raises an error when building random forest and model tuning.
## i store the train and test data to new variabel so the old one remain reproducible
train_tune <- train
test_tune <- test
colnames(train_tune) <- make.names(colnames(train_tune))
colnames(test_tune) <- make.names(colnames(test_tune))
# build 5 folds cross validation for tuning evaluation
set.seed(1502)
folds <- vfold_cv(train_tune, 5)
str(train_tune$labelY)
mod.rf <- rand_forest(trees = 550, mtry = 6, mode = "classification") %>%
set_engine("ranger") %>% fit(labelY~., data = train_tune)
pred.rf <- predict(mod.rf, test_tune,
type = "class")
pred.rf.x <- as.data.frame(cbind(pred.rf, test_tune$labelY)) %>%
setNames(c("pred","actual"))
pred.rf.x
cf.rf <- confusionMatrix(data = pred.rf.x$pred,
reference = pred.rf.x$actual)
cf.rf
library(ggpubr)
ggdensity(dat$rating)
ggdensity(dat$rating)
ggdensity(as.integer(dat$rating))
hist(dat$rating)
hist(as.integer(dat$rating))
table(dat$rating)
prop.table(table(dat$rating))
table(dat$rating)
hist(as.integer(dat$rating))
hist(pred.nb.x$pred)
hist(as.integer(pred.nb.x$pred))
hist(as.integer(dat$rating))
hist(as.integer(pred.nb.x$pred))
hist(as.integer(pred.nb.x$pred))
table(dat$rating)
table(as.integer(pred.nb.x$pred))
table(as.integer(pred.rf.x$pred))
table(as.integer(pred.nb.x$pred))
table(test$rating)
table(test$labelY)
table(test$labelY)
table(as.integer(pred.nb.x$pred))
review.dtm
install.packages("topicmodels")
library(topicmodels)
dat_5 <- dat %>% filter(rating == 5)
head(dat_5)
table(dat$rating)
dat_4 <- dat %>% filter(rating == 4)
dat_3 <- dat %>% filter(rating == 3)
dat_2 <- dat %>% filter(rating == 2)
dat_1 <- dat %>% filter(rating == 1)
str(dat_1)
dat_5_dtm <- textcleaner(dat_5$review)
dat_5_dtm
lda_5 <- LDA(dat_5_dtm, k = 5, control = list(seed=1502))
library(tidytext)
topic_5 <- tidy(lda_5,matrix="beta")
topic_5
freqterm_5 <- findFreqTerms(dat_5_dtm, 15)
freqterm_5 <- findFreqTerms(dat_5_dtm, 10)
dat_5_dtm <- dat_5_dtm[,freqterm_5]
dat_5_dtm
lda_5 <- LDA(dat_5_dtm, k = 5, control = list(seed=1502))
lda_5 <- LDA(dat_5_dtm, k = 3, control = list(seed=1502))
dat_5_dtm
dat_5_dtm <- textcleaner(dat_5$review)
dat_5_dtm
freqterm_5 <- findFreqTerms(dat_5_dtm, 5)
dat_5_dtm <- dat_5_dtm[,freqterm_5]
dat_5_dtm
lda_5 <- LDA(dat_5_dtm, k = 3, control = list(seed=1502))
lda_5 <- LDA(dat_5_dtm, k = 5, control = list(seed=1502))
row_num5 <- apply(dat_5_dtm,1,sum)
dat_5_dtm <- dat_5_dtm[row_num5>0,]
lda_5 <- LDA(dat_5_dtm, k = 5, control = list(seed=1502))
topic_5 <- tidy(lda_5,matrix="beta")
topic_5
library(ggplot2)
top_terms_5 <- topic_5 %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms_5 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
dat_1_dtm <- textcleaner(dat_1$review)
freqterm_1 <- findFreqTerms(dat_1_dtm, 5)
freqterm_1 <- findFreqTerms(dat_1_dtm, 3)
dat_1_dtm <- dat_1_dtm[,freqterm_1]
dat_1_dtm <- dat_1_dtm[row_num1>0,]
row_num1 <- apply(dat_1_dtm,1,sum)
dat_1_dtm <- dat_1_dtm[row_num1>0,]
lda_1 <- LDA(dat_1_dtm, k = 5, control = list(seed=1502))
topic_1 <- tidy(lda_1,matrix="beta")
top_terms_1 <- topic_1 %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms_1 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
dat_1
knitr::opts_chunk$set(echo = TRUE,
fig.align = "center")
options(scipen = 999)
# cek proporsi review sesuai rating
table(dat$rating)
# hasil data bersih yang sudah diberi token
# tiap baris menunjukkan 1 review user
head(new.dat)
cf.nb
cf.rf
table(test_tune$labelY)
cf.nb$byClass
cf.nb$table
cf.nb$dots
cf.nb$mode
cf.nb$overall
df.nb <- data.frame(t(as.matrix(cf.nb, what = "overall")))
df.nb
df.nb
df.nb <- data.frame(t(as.matrix(cf.nb, what = "overall")))
df.rf <- data.frame(t(as.matrix(cf.rf, what = "overall")))
all.eval <- rbind(Naive_Bayes = df.nb,
Random_Forest = df.rf) %>%
select("Accuracy") %>% data.frame()
all.eval
top_terms_5 <- topic_5 %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms_5 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
top_terms_5 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
labs(title = "Topik pembicaraan pada review di rating 5")
top_terms_5 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
labs(title = "Topik pembicaraan pada review di rating 5",
subtitle = "Produk sunscreen Emina")
top_terms_5 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
labs(title = "Topik pembicaraan pada review di rating 5 FemaleDaily",
subtitle = "Produk sunscreen Emina")
top_terms_1 <- topic_1 %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms_1 %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered() +
labs(title = "Topik pembicaraan pada review di rating 1 FemaleDaily",
subtitle = "Produk sunscreen Emina")
