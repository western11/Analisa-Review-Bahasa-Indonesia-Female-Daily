---
title: "Analisa review pengguna produk kecantikan sunscreen di FemaleDaily.com"
author: "Lydiu"
date: "5/6/2020"
output:
  html_document:
   toc: true
   toc_float: true
   toc_depth: 2
   theme: flatly
   highlight: zenburn
   df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center")

options(scipen = 999)
```

# Background {.tabset}
## Objective
Projek ini bertujuan untuk:   
- Mencari topik yang dibicarakan user FemaleDaily.com pada setiap rating (topic modeling)   
- Bagaimana Sentiment yang diberikan user dapat memprediksi rating   
- Membangun model dengan akurasi terbaik dalam memprediksi rating produk

Data bersumber dari FemaleDaily.com dengan 3 produk yang berbeda. Data berisi review (teks) dan rating pengguna berbahasa Indonesia. Data akan diolah terpisah untuk menjawab pertanyaan penelitian/objective dari projek

## Library
Berikut library yang digunakan. jika library tidak tersedia lakukan
```{r}
#install.packages("nama library")
```

```{r warning=FALSE, message=FALSE}
library(dplyr)
library(textclean)
library(tm)
library(SnowballC)
library(stringr)
library(e1071)
library(tidymodels)
library(caret)
```

# Data Import
```{r}
# import data
dat <- read.csv("emina1.csv")
# rename kolom, subset, dan menghilangkan baris yang mempunyai missing value
dat <- dat %>% rename(
  "review" = "Ã¯..review"
) %>% select(review,rating) %>%
  na.omit()
# mengubah tipe kolom rating menjadi factor
dat$rating <- as.factor(dat$rating)
# cek jumlah review sesuai rating
table(dat$rating)
```
import stopwords bahasa Indonesia
```{r}
# add custom bahasa stopwords
bahasa.sw <- read.csv("Bahasa.stopwords.csv", header = F,fileEncoding = "UTF-8-BOM")
bahasa.sw <- as.character(bahasa.sw$V1)
bahasa.sw <- c(bahasa.sw, stopwords())
```

Import stemming dan slangword converter bahasa Indonesia
```{r}
# add custom stemming and slangword bahasa indonesia
stemm_indo <- read.csv("Stemming.csv")
oldstem <- as.character(stemm_indo$old)
newstem <- as.character(stemm_indo$new)

slang_indo <- read.csv("Slangword.csv")
oldslang <- as.character(slang_indo$old)
newslang <- as.character(slang_indo$new)
```

contoh review
```{r}
head(dat$review)
```

# Text Cleaning
Teks perlu dibersihkan sebelum dilakukan topic modeling dan prediksi. Tahap pembersihan yang dilakukan adalah:    
- Mengubah seluruh teks menjadi huruf kecil (lower)   
- Mengubah contraction (contoh: i've -> i have, you're -> you are)   
- mengubah slang words (contoh: gw -> aku, bgt -> banget, bagussss -> bagus)   
- menghapus emoji, emoticon, hash, angka, date, time, dan punctuation (/ , . " ;)   
- menghapus spasi berlebih antar kata (whitespace)   
- menghapus imbuhan (contoh: membeli -> beli, harganya -> harga)   
Setelah dibersihkan, data lalu dirubah ke bentuk corpus dan melakukan tokenization (perhitungan jumlah per kata dalam tiap review). Proses pembersihan sampai pembentukan corpus dibuat kedalam function `textcleaner` agar function bisa digunakan untuk tahapan selanjutnya. 

## membuat `textcleaner` function
```{r}
# membuat function untuk stemming bahasa Indonesia
stemmword <- function(x) Reduce(function(x,r) gsub(stemm_indo$old[r],stemm_indo$new[r],x,fixed=T),
seq_len(nrow(stemm_indo)),x)

# membuat function untuk konversi slangword bahasa Indonesia
slangword <- function(x) Reduce(function(x,r) gsub(slang_indo$old[r],slang_indo$new[r],x,fixed=T),
seq_len(nrow(slang_indo)),x)

# membuat function textcleaner
textcleaner <- function(x){
  x <- as.character(x)
  
  x <- x %>%
    str_to_lower() %>%  # convert all the string to low alphabet
    replace_contraction() %>% # replace contraction to their multi-word forms
    replace_internet_slang() %>% # replace internet slang to normal words
    replace_emoji() %>% # replace emoji to words
    replace_emoticon() %>% # replace emoticon to words
    replace_hash(replacement = "") %>% # remove hashtag
    replace_word_elongation() %>% # replace informal writing with known semantic replacements
    replace_number(remove = T) %>% # remove number
    replace_date(replacement = "") %>% # remove date
    replace_time(replacement = "") %>% # remove time
    str_remove_all(pattern = "[[:punct:]]") %>% # remove punctuation
    str_remove_all(pattern = "[^\\s]*[0-9][^\\s]*") %>% # remove mixed string n number
    str_squish() %>% # reduces repeated whitespace inside a string.
    str_trim() # removes whitespace from start and end of string
  
  xdtm <- VCorpus(VectorSource(x)) %>%
    tm_map(removeWords, stopwords("en")) %>%
    tm_map(removeWords, bahasa.sw) %>%
    tm_map(removePunctuation) %>%
    tm_map(content_transformer(stemmword)) %>%
    tm_map(content_transformer(slangword))
  
  # mengubah corpus menjadi document term matrix
  return(DocumentTermMatrix(xdtm))
    
}

```

## proses cleaning
```{r}
# mengaplikasikan function textclean ke review produk
review.dtm <- textcleaner(dat$review)
# filter terms frequency. hanya mengambil kata yang ada di lebih dari 15 review
freqterm <- findFreqTerms(review.dtm, 15)
dat_dtm <- review.dtm[,freqterm]
```

```{r}
# mengubah term matrix menjadi dataframe untuk modeling
dat.clean <- as.data.frame(as.matrix(dat_dtm), stringsAsFactors = F)
# we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names
new.dat <- cbind(dat.clean, data.frame(labelY = dat$rating))
# hasil data bersih yang sudah diberi token
# tiap baris menunjukkan 1 review user
head(new.dat)
```

# Modeling
Untuk menjawab pertanyaan penelitian 1 dan 2, dilakukan modeling dengan algoritma Naive Bayes dan Random Forest (more model soon). Akurasi model didapat dari prediksi test data (unseen data). **Note:** metode yang dilakukan ada klasifikasi, jadi rating dianggap tidak mempunyai level. rating 1 akan dianggap sama dengan rating 5 and vice versa

## splitting
split data menjadi data train dan test dengan proporsi 75% dan 25%. data train digunakan untuk membangun model dan test untuk evaluasi model (prediksi)
```{r}
set.seed(1502)
splitter <- initial_split(new.dat, prop = 0.75, strata = "labelY")
train <- training(splitter)
test <- testing(splitter)
```


## Naive Bayes
Naive bayes membutuhkan format data yang berbeda. Naive bayes tidak membutuhkan frekuensi token. token hanya berisi 1 dan 0, 1 menunjukkan kata tersebut ada didalam kalimat dan 0 brarti tidak ada kehadiran kata tersebut
```{r}
# split the data. 75% for train data, and 25% for test data
set.seed(1502)
index <- sample(1:nrow(dat_dtm), 0.75*nrow(dat_dtm))

train_x <- dat_dtm[index,]
test_x <- dat_dtm[-index,]
# subset label/target variable
train_label <- dat[index,"rating"]
test_label <- dat[-index,"rating"]
```

Use bernoulli converter to convert any value above 0 to 1 and 0 to remain 0.
```{r}
# bernoulli conv 
bernoulli_conv <- function(x){
  x <- as.factor(as.numeric(x>0))
}
```

apply bernoulli converter to train and test data
```{r}
train_x <- apply(train_x,2,bernoulli_conv)
test_x <- apply(test_x,2,bernoulli_conv)
```

Membangun model naive bayes
```{r}
# train the model
mod.nb <- naiveBayes(train_x, as.factor(train_label), laplace = 1)

# predict to test data
pred.nb <- predict(mod.nb, test_x,
                   type = "class")

pred.nb.x <- cbind(data.frame(pred.nb),as.factor(test_label))%>%
  setNames(c("pred","actual"))

pred.nb.x
```

Membuat confusion matrix untuk evaluasi hasil prediksi model
```{r}
cf.nb <- confusionMatrix(data = pred.nb.x$pred,
                         reference = pred.nb.x$actual)
cf.nb
```

Model Naive Bayes mendapatkan akurasi 45.1 %. False negatives dan positives banyak terdapat di rating 4 & 5, ini menunjukkan model kesulitan untuk membedakan review dengan rating 4 dan 5. Akurasi yang rendah juga terjadi karena data rating tidak seimbang (rating 4 jauh lebih banyak dari rating 1)

## Random Forest
model random forest dengan mesin `ranger` tidak dapat menerima nama kolom dengan special character seperti for, break, next, return, dll. Perlu dilakukan koversi nama kolom menjadi nama yang bukan special character
```{r}
# this chunks are made for random forest model and future model tuning
## the column names like break,for,next,if are considered as special character thus raises an error when building random forest and model tuning.
## i store the train and test data to new variabel so the old one remain reproducible
train_tune <- train
test_tune <- test

colnames(train_tune) <- make.names(colnames(train_tune))
colnames(test_tune) <- make.names(colnames(test_tune))

# build 5 folds cross validation for tuning evaluation
set.seed(1502)
folds <- vfold_cv(train_tune, 5)
```

Membangun model Random Forest
```{r}
mod.rf <- rand_forest(trees = 550, mtry = 6, mode = "classification") %>%
  set_engine("ranger") %>% fit(labelY~., data = train_tune)

pred.rf <- predict(mod.rf, test_tune, 
                   type = "class")

pred.rf.x <- as.data.frame(cbind(pred.rf, test_tune$labelY)) %>%
  setNames(c("pred","actual"))

pred.rf.x
```

Membuat confusion matrix untuk evaluasi hasil prediksi model
```{r}
cf.rf <- confusionMatrix(data = pred.rf.x$pred,
                         reference = pred.rf.x$actual)
cf.rf
```

Model Random Forest mendapatkan akuras 44.5 % sedikit lebih buruk dari naive bayes. Model ini sama sekali tidak memperdiksi rating 1 (rating dengan proporsi paling kecil). Model terlalu banyak memprediksi rating 4 (rating dengan proporsi paling banyak) yang mengakibatkan akurasi menjadi kecil.

## Model Conclusion
Mengkombinasikan hasil confusion matrix
```{r}
df.nb <- data.frame(t(as.matrix(cf.nb, what = "overall")))
df.rf <- data.frame(t(as.matrix(cf.rf, what = "overall")))

all.eval <- rbind(Naive_Bayes = df.nb, 
                  Random_Forest = df.rf) %>%
  select("Accuracy") %>% data.frame()

all.eval
```

Dari tabel diatas dapat ditarik kesimpulan model `Naive Bayes` lebih baik dari pada `Random Forest` dalam memprediksi rating berdasarkan teks review

# Topic Modeling
Topic modeling dilakukan untuk menjawab pertanyaan penelitian nomor 1, yaitu **Apa topik yang dibicarakan user FemaleDaily.com pada setiap rating?** Algoritma yang digunakan untuk mencari topic modeling adalah *Latent Dirichlet Allocation (LDA)*. LDA adalah model matematika yang digunakan untuk menemukan campuran kata yang terkait dengan setiap topik, juga menentukan campuran topik yang menggambarkan setiap dokumen. LDA bekerja untuk menjawab 2 prinsip topic modeling berikut:   

- Every document is a mixture of topics   
- Every topic is a mixture of words   


load library yang dibutuhkan
```{r warning=FALSE, message=FALSE}
library(topicmodels)
library(tidytext)
library(ggplot2)
```

Memisahkan review berdasarkan rating
```{r}
dat_5 <- dat %>% filter(rating == 5)
dat_4 <- dat %>% filter(rating == 4)
dat_3 <- dat %>% filter(rating == 3)
dat_2 <- dat %>% filter(rating == 2)
dat_1 <- dat %>% filter(rating == 1)
```

## Topic modeling rating 5
Sebelum melakukan topic modeling, perlu dilakukan pembersihan teks sama seperti modeling prediksi di tahap sebelumnya. Di modeling prediksi pembersihan dilakukan seara menyeluruh tanpa melihat rating. Disini dilakukan pembersihan ulang dengan data yang sudah di subset. Pengerjan topic modeling akan dibuat 5x sesuai banyak rating

Proses pembersihan teks
```{r}
# mengaplikasikan function textcleaner pada review dengan rating 5
dat_5_dtm <- textcleaner(dat_5$review)
# Filter kata yang ada di lebih dari 5 review
freqterm_5 <- findFreqTerms(dat_5_dtm, 5)
dat_5_dtm <- dat_5_dtm[,freqterm_5]
# setelah filtering akan ada data sisa tanpa isi token. data sperti itu akan dihilangkan
row_num5 <- apply(dat_5_dtm,1,sum)
dat_5_dtm <- dat_5_dtm[row_num5>0,]
```

mengaplikasikan algoritma LDA untuk mencari topic modeling. Disini akan dibuat 5 topik pembicaraan pada setiap rating
```{r}
lda_5 <- LDA(dat_5_dtm, k = 5, control = list(seed=1502))
topic_5 <- tidy(lda_5,matrix="beta")
```

Membuat visualisasi topik yang dibicarakan
```{r}
top_terms_5 <- topic_5 %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_5 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topik pembicaraan pada review di rating 5 FemaleDaily",
       subtitle = "Produk sunscreen Emina")
```


## Topic modeling rating 1

Proses pembersihan teks
```{r}
# mengaplikasikan function textcleaner pada review dengan rating 5
dat_1_dtm <- textcleaner(dat_1$review)
# Filter kata yang ada di lebih dari 5 review
freqterm_1 <- findFreqTerms(dat_1_dtm, 3)
dat_1_dtm <- dat_1_dtm[,freqterm_1]
# setelah filtering akan ada data sisa tanpa isi token. data sperti itu akan dihilangkan
row_num1 <- apply(dat_1_dtm,1,sum)
dat_1_dtm <- dat_1_dtm[row_num1>0,]
```

mengaplikasikan algoritma LDA untuk mencari topic modeling. Disini akan dibuat 5 topik pembicaraan pada setiap rating
```{r}
lda_1 <- LDA(dat_1_dtm, k = 5, control = list(seed=1502))
topic_1 <- tidy(lda_1,matrix="beta")
```

Membuat visualisasi topik yang dibicarakan
```{r}
top_terms_1 <- topic_1 %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_1 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Topik pembicaraan pada review di rating 1 FemaleDaily",
       subtitle = "Produk sunscreen Emina")
```

# Reference:   
- [textclean R](https://cran.r-project.org/web/packages/textclean/readme/README.html)
- [Topic Modelling with tidytext R](https://www.tidytextmining.com/topicmodeling.html#latent-dirichlet-allocation)

